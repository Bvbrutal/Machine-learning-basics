{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 50\u001B[0m\n\u001B[0;32m     46\u001B[0m test_x \u001B[38;5;241m=\u001B[39m scaler\u001B[38;5;241m.\u001B[39mfit_transform(test_images)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# 划分训练集和测试集\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mX\u001B[49m, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m7\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# 数据预处理：标准化\u001B[39;00m\n\u001B[0;32m     53\u001B[0m scaler \u001B[38;5;241m=\u001B[39m StandardScaler()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#实践部分\n",
    "import struct\n",
    "import os\n",
    "#fucntion to load MNIST data\n",
    "def load_mnist_data(path,kind='train'):\n",
    "    label_path = os.path.join(path, '%s-labels.idx1-ubyte'%kind)\n",
    "    image_path = os.path.join(path, '%s-images.idx3-ubyte'%kind)\n",
    "    with open(label_path,'rb') as lbpath: # open label file\n",
    "        struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,dtype=np.uint8)\n",
    "    with open(image_path,'rb') as imgpath:# open image file\n",
    "        struct.unpack('>IIII', imgpath.read(16))\n",
    "        #transform image into 784-dimensional feature vector\n",
    "        images = np.fromfile(imgpath,dtype=np.uint8).reshape(len(labels),784)\n",
    "    return images,labels\n",
    "\n",
    "#定义图片显示函数\n",
    "import matplotlib.pyplot as plt\n",
    "def show_image(image):\n",
    "    plt.figure()\n",
    "    img = image.reshape(28,28)\n",
    "    plt.imshow(img, 'gray')\n",
    "    plt.show()\n",
    "#数据读取和预处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "path = 'MNIST'\n",
    "train_images, train_labels = load_mnist_data(path,kind='train')\n",
    "# show_image(train_images)\n",
    "train_y = np.zeros((len(train_labels),10))\n",
    "for i in range(len(train_labels)):\n",
    "    train_y[i,train_labels[i]]=1\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_images)\n",
    "test_images, test_labels = load_mnist_data(path,kind='t10k')\n",
    "# show_image(test_images)\n",
    "test_y = np.zeros((len(test_labels),10))\n",
    "for i in range(len(test_labels)):\n",
    "    test_y[i,test_labels[i]]=1\n",
    "test_x = scaler.fit_transform(test_images)\n",
    "\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=42)\n",
    "\n",
    "# 数据预处理：标准化\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 训练和评估模型\n",
    "def train_and_evaluate(hidden_layer_sizes, activation):\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, max_iter=100, random_state=1)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# 比较不同层数的模型\n",
    "accuracy_1_layer = train_and_evaluate((50,), 'relu')\n",
    "accuracy_2_layers = train_and_evaluate((50, 50), 'relu')\n",
    "\n",
    "print(\"Accuracy with 1 hidden layer:\", accuracy_1_layer)\n",
    "print(\"Accuracy with 2 hidden layers:\", accuracy_2_layers)\n",
    "\n",
    "# 比较不同激活函数的模型\n",
    "accuracy_relu = train_and_evaluate((50,), 'relu')\n",
    "accuracy_tanh = train_and_evaluate((50,), 'tanh')\n",
    "\n",
    "print(\"Accuracy with ReLU activation:\", accuracy_relu)\n",
    "print(\"Accuracy with Tanh activation:\", accuracy_tanh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 加载并准备MNIST数据集\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# 定义一个函数来创建模型\n",
    "def create_model(layers, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28 * 28,)))\n",
    "    for layer_size in layers:\n",
    "        model.add(Dense(layer_size, activation=activation))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# 比较不同层数和激活函数的模型\n",
    "layer_configs = [(32,), (64, 32), (128, 64, 32)]  # 不同的层配置\n",
    "activations = ['relu', 'sigmoid', 'tanh']  # 不同的激活函数\n",
    "for layers in layer_configs:\n",
    "    for activation in activations:\n",
    "        model = create_model(layers, activation)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(train_images, train_labels, epochs=5, batch_size=128, validation_split=0.2)\n",
    "        test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "        print(f'Layers: {layers}, Activation: {activation}, Test accuracy: {test_acc}')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
